{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee2b88ca",
   "metadata": {},
   "source": [
    "# Kepler KOI Dataset Columns\n",
    "\n",
    "- **kepid**: KepID  \n",
    "- **kepoi_name**: KOI Name  \n",
    "- **kepler_name**: Kepler Name  \n",
    "- **koi_disposition**: Exoplanet Archive Disposition  \n",
    "- **koi_pdisposition**: Disposition Using Kepler Data  \n",
    "- **koi_score**: Disposition Score  \n",
    "- **koi_fpflag_nt**: Not Transit-Like False Positive Flag  \n",
    "- **koi_fpflag_ss**: Stellar Eclipse False Positive Flag  \n",
    "- **koi_fpflag_co**: Centroid Offset False Positive Flag  \n",
    "- **koi_fpflag_ec**: Ephemeris Match Indicates Contamination False Positive Flag  \n",
    "- **koi_period**: Orbital Period [days]  \n",
    "- **koi_period_err1**: Orbital Period Upper Uncertainty [days]  \n",
    "- **koi_period_err2**: Orbital Period Lower Uncertainty [days]  \n",
    "- **koi_time0bk**: Transit Epoch [BKJD]  \n",
    "- **koi_time0bk_err1**: Transit Epoch Upper Uncertainty [BKJD]  \n",
    "- **koi_time0bk_err2**: Transit Epoch Lower Uncertainty [BKJD]  \n",
    "- **koi_impact**: Impact Parameter  \n",
    "- **koi_impact_err1**: Impact Parameter Upper Uncertainty  \n",
    "- **koi_impact_err2**: Impact Parameter Lower Uncertainty  \n",
    "- **koi_duration**: Transit Duration [hrs]  \n",
    "- **koi_duration_err1**: Transit Duration Upper Uncertainty [hrs]  \n",
    "- **koi_duration_err2**: Transit Duration Lower Uncertainty [hrs]  \n",
    "- **koi_depth**: Transit Depth [ppm]  \n",
    "- **koi_depth_err1**: Transit Depth Upper Uncertainty [ppm]  \n",
    "- **koi_depth_err2**: Transit Depth Lower Uncertainty [ppm]  \n",
    "- **koi_prad**: Planetary Radius [Earth radii]  \n",
    "- **koi_prad_err1**: Planetary Radius Upper Uncertainty [Earth radii]  \n",
    "- **koi_prad_err2**: Planetary Radius Lower Uncertainty [Earth radii]  \n",
    "- **koi_teq**: Equilibrium Temperature [K]  \n",
    "- **koi_teq_err1**: Equilibrium Temperature Upper Uncertainty [K]  \n",
    "- **koi_teq_err2**: Equilibrium Temperature Lower Uncertainty [K]  \n",
    "- **koi_insol**: Insolation Flux [Earth flux]  \n",
    "- **koi_insol_err1**: Insolation Flux Upper Uncertainty [Earth flux]  \n",
    "- **koi_insol_err2**: Insolation Flux Lower Uncertainty [Earth flux]  \n",
    "- **koi_model_snr**: Transit Signal-to-Noise  \n",
    "- **koi_tce_plnt_num**: TCE Planet Number  \n",
    "- **koi_tce_delivname**: TCE Delivery  \n",
    "- **koi_steff**: Stellar Effective Temperature [K]  \n",
    "- **koi_steff_err1**: Stellar Effective Temperature Upper Uncertainty [K]  \n",
    "- **koi_steff_err2**: Stellar Effective Temperature Lower Uncertainty [K]  \n",
    "- **koi_slogg**: Stellar Surface Gravity [log10(cm/s²)]  \n",
    "- **koi_slogg_err1**: Stellar Surface Gravity Upper Uncertainty [log10(cm/s²)]  \n",
    "- **koi_slogg_err2**: Stellar Surface Gravity Lower Uncertainty [log10(cm/s²)]  \n",
    "- **koi_srad**: Stellar Radius [Solar radii]  \n",
    "- **koi_srad_err1**: Stellar Radius Upper Uncertainty [Solar radii]  \n",
    "- **koi_srad_err2**: Stellar Radius Lower Uncertainty [Solar radii]  \n",
    "- **ra**: Right Ascension [decimal degrees]  \n",
    "- **dec**: Declination [decimal degrees]  \n",
    "- **koi_kepmag**: Kepler-band Magnitude [mag]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1070a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8666a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f4de7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_rowid</th>\n",
       "      <th>kepid</th>\n",
       "      <th>kepoi_name</th>\n",
       "      <th>kepler_name</th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_pdisposition</th>\n",
       "      <th>koi_score</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10797460</td>\n",
       "      <td>K00752.01</td>\n",
       "      <td>Kepler-227 b</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10797460</td>\n",
       "      <td>K00752.02</td>\n",
       "      <td>Kepler-227 c</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10811496</td>\n",
       "      <td>K00753.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10848459</td>\n",
       "      <td>K00754.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10854555</td>\n",
       "      <td>K00755.01</td>\n",
       "      <td>Kepler-664 b</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-211.0</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9559</th>\n",
       "      <td>9560</td>\n",
       "      <td>10090151</td>\n",
       "      <td>K07985.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-166.0</td>\n",
       "      <td>4.529</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>297.18875</td>\n",
       "      <td>47.093819</td>\n",
       "      <td>14.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9560</th>\n",
       "      <td>9561</td>\n",
       "      <td>10128825</td>\n",
       "      <td>K07986.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-220.0</td>\n",
       "      <td>4.444</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>1.031</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>286.50937</td>\n",
       "      <td>47.163219</td>\n",
       "      <td>14.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>9562</td>\n",
       "      <td>10147276</td>\n",
       "      <td>K07987.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-236.0</td>\n",
       "      <td>4.447</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>1.041</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>294.16489</td>\n",
       "      <td>47.176281</td>\n",
       "      <td>15.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9562</th>\n",
       "      <td>9563</td>\n",
       "      <td>10155286</td>\n",
       "      <td>K07988.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-128.0</td>\n",
       "      <td>2.992</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>7.824</td>\n",
       "      <td>0.223</td>\n",
       "      <td>-1.896</td>\n",
       "      <td>296.76288</td>\n",
       "      <td>47.145142</td>\n",
       "      <td>10.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9563</th>\n",
       "      <td>9564</td>\n",
       "      <td>10156110</td>\n",
       "      <td>K07989.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-225.0</td>\n",
       "      <td>4.385</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>1.193</td>\n",
       "      <td>0.410</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>297.00977</td>\n",
       "      <td>47.121021</td>\n",
       "      <td>14.826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9564 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      loc_rowid     kepid kepoi_name   kepler_name koi_disposition  \\\n",
       "0             1  10797460  K00752.01  Kepler-227 b       CONFIRMED   \n",
       "1             2  10797460  K00752.02  Kepler-227 c       CONFIRMED   \n",
       "2             3  10811496  K00753.01           NaN       CANDIDATE   \n",
       "3             4  10848459  K00754.01           NaN  FALSE POSITIVE   \n",
       "4             5  10854555  K00755.01  Kepler-664 b       CONFIRMED   \n",
       "...         ...       ...        ...           ...             ...   \n",
       "9559       9560  10090151  K07985.01           NaN  FALSE POSITIVE   \n",
       "9560       9561  10128825  K07986.01           NaN       CANDIDATE   \n",
       "9561       9562  10147276  K07987.01           NaN  FALSE POSITIVE   \n",
       "9562       9563  10155286  K07988.01           NaN       CANDIDATE   \n",
       "9563       9564  10156110  K07989.01           NaN  FALSE POSITIVE   \n",
       "\n",
       "     koi_pdisposition  koi_score  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  \\\n",
       "0           CANDIDATE      1.000              0              0              0   \n",
       "1           CANDIDATE      0.969              0              0              0   \n",
       "2           CANDIDATE      0.000              0              0              0   \n",
       "3      FALSE POSITIVE      0.000              0              1              0   \n",
       "4           CANDIDATE      1.000              0              0              0   \n",
       "...               ...        ...            ...            ...            ...   \n",
       "9559   FALSE POSITIVE      0.000              0              1              1   \n",
       "9560        CANDIDATE      0.497              0              0              0   \n",
       "9561   FALSE POSITIVE      0.021              0              0              1   \n",
       "9562        CANDIDATE      0.092              0              0              0   \n",
       "9563   FALSE POSITIVE      0.000              0              0              1   \n",
       "\n",
       "      ...  koi_steff_err2  koi_slogg  koi_slogg_err1  koi_slogg_err2  \\\n",
       "0     ...           -81.0      4.467           0.064          -0.096   \n",
       "1     ...           -81.0      4.467           0.064          -0.096   \n",
       "2     ...          -176.0      4.544           0.044          -0.176   \n",
       "3     ...          -174.0      4.564           0.053          -0.168   \n",
       "4     ...          -211.0      4.438           0.070          -0.210   \n",
       "...   ...             ...        ...             ...             ...   \n",
       "9559  ...          -166.0      4.529           0.035          -0.196   \n",
       "9560  ...          -220.0      4.444           0.056          -0.224   \n",
       "9561  ...          -236.0      4.447           0.056          -0.224   \n",
       "9562  ...          -128.0      2.992           0.030          -0.027   \n",
       "9563  ...          -225.0      4.385           0.054          -0.216   \n",
       "\n",
       "      koi_srad  koi_srad_err1  koi_srad_err2         ra        dec  koi_kepmag  \n",
       "0        0.927          0.105         -0.061  291.93423  48.141651      15.347  \n",
       "1        0.927          0.105         -0.061  291.93423  48.141651      15.347  \n",
       "2        0.868          0.233         -0.078  297.00482  48.134129      15.436  \n",
       "3        0.791          0.201         -0.067  285.53461  48.285210      15.597  \n",
       "4        1.046          0.334         -0.133  288.75488  48.226200      15.509  \n",
       "...        ...            ...            ...        ...        ...         ...  \n",
       "9559     0.903          0.237         -0.079  297.18875  47.093819      14.082  \n",
       "9560     1.031          0.341         -0.114  286.50937  47.163219      14.757  \n",
       "9561     1.041          0.341         -0.114  294.16489  47.176281      15.385  \n",
       "9562     7.824          0.223         -1.896  296.76288  47.145142      10.998  \n",
       "9563     1.193          0.410         -0.137  297.00977  47.121021      14.826  \n",
       "\n",
       "[9564 rows x 50 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Data\\cumulative_2025.10.03_07.59.03.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "47754838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9564 entries, 0 to 9563\n",
      "Data columns (total 50 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   loc_rowid          9564 non-null   int64  \n",
      " 1   kepid              9564 non-null   int64  \n",
      " 2   kepoi_name         9564 non-null   object \n",
      " 3   kepler_name        2747 non-null   object \n",
      " 4   koi_disposition    9564 non-null   object \n",
      " 5   koi_pdisposition   9564 non-null   object \n",
      " 6   koi_score          8054 non-null   float64\n",
      " 7   koi_fpflag_nt      9564 non-null   int64  \n",
      " 8   koi_fpflag_ss      9564 non-null   int64  \n",
      " 9   koi_fpflag_co      9564 non-null   int64  \n",
      " 10  koi_fpflag_ec      9564 non-null   int64  \n",
      " 11  koi_period         9564 non-null   float64\n",
      " 12  koi_period_err1    9110 non-null   float64\n",
      " 13  koi_period_err2    9110 non-null   float64\n",
      " 14  koi_time0bk        9564 non-null   float64\n",
      " 15  koi_time0bk_err1   9110 non-null   float64\n",
      " 16  koi_time0bk_err2   9110 non-null   float64\n",
      " 17  koi_impact         9201 non-null   float64\n",
      " 18  koi_impact_err1    9110 non-null   float64\n",
      " 19  koi_impact_err2    9110 non-null   float64\n",
      " 20  koi_duration       9564 non-null   float64\n",
      " 21  koi_duration_err1  9110 non-null   float64\n",
      " 22  koi_duration_err2  9110 non-null   float64\n",
      " 23  koi_depth          9201 non-null   float64\n",
      " 24  koi_depth_err1     9110 non-null   float64\n",
      " 25  koi_depth_err2     9110 non-null   float64\n",
      " 26  koi_prad           9201 non-null   float64\n",
      " 27  koi_prad_err1      9201 non-null   float64\n",
      " 28  koi_prad_err2      9201 non-null   float64\n",
      " 29  koi_teq            9201 non-null   float64\n",
      " 30  koi_teq_err1       0 non-null      float64\n",
      " 31  koi_teq_err2       0 non-null      float64\n",
      " 32  koi_insol          9243 non-null   float64\n",
      " 33  koi_insol_err1     9243 non-null   float64\n",
      " 34  koi_insol_err2     9243 non-null   float64\n",
      " 35  koi_model_snr      9201 non-null   float64\n",
      " 36  koi_tce_plnt_num   9218 non-null   float64\n",
      " 37  koi_tce_delivname  9218 non-null   object \n",
      " 38  koi_steff          9201 non-null   float64\n",
      " 39  koi_steff_err1     9096 non-null   float64\n",
      " 40  koi_steff_err2     9081 non-null   float64\n",
      " 41  koi_slogg          9201 non-null   float64\n",
      " 42  koi_slogg_err1     9096 non-null   float64\n",
      " 43  koi_slogg_err2     9096 non-null   float64\n",
      " 44  koi_srad           9201 non-null   float64\n",
      " 45  koi_srad_err1      9096 non-null   float64\n",
      " 46  koi_srad_err2      9096 non-null   float64\n",
      " 47  ra                 9564 non-null   float64\n",
      " 48  dec                9564 non-null   float64\n",
      " 49  koi_kepmag         9563 non-null   float64\n",
      "dtypes: float64(39), int64(6), object(5)\n",
      "memory usage: 3.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38b9375",
   "metadata": {},
   "source": [
    "# ExoNet Feature Mapping (KOI Dataset → Model Usage)\n",
    "\n",
    "| KOI Column         | Description                                    | ExoNet Usage        |\n",
    "|--------------------|------------------------------------------------|---------------------|\n",
    "| **koi_period**     | Orbital Period [days]                          | Core Input Feature  |\n",
    "| **koi_duration**   | Transit Duration [hrs]                         | Core Input Feature  |\n",
    "| **koi_depth**      | Transit Depth [ppm]                            | Core Input Feature  |\n",
    "| **koi_prad**       | Planetary Radius [Earth radii]                 | Core Input Feature  |\n",
    "| **koi_model_snr**  | Transit Signal-to-Noise                        | Core Input Feature  |\n",
    "| **koi_time0bk**    | Transit Epoch [BKJD]                           | Auxiliary Input (for phase folding / alignment) |\n",
    "| **koi_impact**     | Impact Parameter                               | Auxiliary Input     |\n",
    "| **koi_steff**      | Stellar Effective Temperature [K]              | Context Feature     |\n",
    "| **koi_slogg**      | Stellar Surface Gravity [log10(cm/s²)]         | Context Feature     |\n",
    "| **koi_srad**       | Stellar Radius [Solar radii]                   | Context Feature     |\n",
    "| **koi_kepmag**     | Kepler-band Magnitude [mag]                    | Context Feature (affects noise/SNR) |\n",
    "| **koi_disposition**| Exoplanet Archive Disposition (Confirmed / Candidate / False Positive) | Label (Target) |\n",
    "| **koi_pdisposition** | Disposition Using Kepler Data                | Label / Validation Reference |\n",
    "| **koi_score**      | Disposition Score (confidence metric)          | Label Confidence / Training Weight |\n",
    "| **koi_fpflag_nt**  | Not Transit-Like False Positive Flag           | Label Metadata (helps refine negatives) |\n",
    "| **koi_fpflag_ss**  | Stellar Eclipse False Positive Flag            | Label Metadata      |\n",
    "| **koi_fpflag_co**  | Centroid Offset False Positive Flag            | Label Metadata      |\n",
    "| **koi_fpflag_ec**  | Ephemeris Match Contamination False Positive Flag | Label Metadata  |\n",
    "\n",
    "---\n",
    "\n",
    "## Notes for ExoNet\n",
    "- **Core Input Features** → go directly into the tabular branch of the model.  \n",
    "- **Auxiliary Input Features** → used during preprocessing (e.g., phase folding, alignment).  \n",
    "- **Context Features** → provide stellar/observational context for classification (help distinguish planet vs binary vs noise).  \n",
    "- **Labels / Metadata** → used for supervised training, calibration, and evaluation.  \n",
    "\n",
    "Final model pipeline:  \n",
    "- Tabular features (`period`, `duration`, `depth`, `radius`, `SNR`, + stellar context)  \n",
    "- CNN embeddings from folded light curves  \n",
    "- Fusion layer → classifier → outputs **Calibrated Probabilities (planet / candidate / false positive)**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "73a36e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected shape: (9564, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_kepmag</th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_pdisposition</th>\n",
       "      <th>koi_score</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.488036</td>\n",
       "      <td>2.95750</td>\n",
       "      <td>615.8</td>\n",
       "      <td>2.26</td>\n",
       "      <td>35.8</td>\n",
       "      <td>170.538750</td>\n",
       "      <td>0.146</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>15.347</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.418383</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>874.8</td>\n",
       "      <td>2.83</td>\n",
       "      <td>25.8</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.586</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>15.347</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>76.3</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.969</td>\n",
       "      <td>5853.0</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.868</td>\n",
       "      <td>15.436</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>8079.2</td>\n",
       "      <td>33.46</td>\n",
       "      <td>505.6</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>1.276</td>\n",
       "      <td>5805.0</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.791</td>\n",
       "      <td>15.597</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.525592</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>603.3</td>\n",
       "      <td>2.75</td>\n",
       "      <td>40.9</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.701</td>\n",
       "      <td>6031.0</td>\n",
       "      <td>4.438</td>\n",
       "      <td>1.046</td>\n",
       "      <td>15.509</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   koi_period  koi_duration  koi_depth  koi_prad  koi_model_snr  koi_time0bk  \\\n",
       "0    9.488036       2.95750      615.8      2.26           35.8   170.538750   \n",
       "1   54.418383       4.50700      874.8      2.83           25.8   162.513840   \n",
       "2   19.899140       1.78220    10829.0     14.60           76.3   175.850252   \n",
       "3    1.736952       2.40641     8079.2     33.46          505.6   170.307565   \n",
       "4    2.525592       1.65450      603.3      2.75           40.9   171.595550   \n",
       "\n",
       "   koi_impact  koi_steff  koi_slogg  koi_srad  koi_kepmag koi_disposition  \\\n",
       "0       0.146     5455.0      4.467     0.927      15.347       CONFIRMED   \n",
       "1       0.586     5455.0      4.467     0.927      15.347       CONFIRMED   \n",
       "2       0.969     5853.0      4.544     0.868      15.436       CANDIDATE   \n",
       "3       1.276     5805.0      4.564     0.791      15.597  FALSE POSITIVE   \n",
       "4       0.701     6031.0      4.438     1.046      15.509       CONFIRMED   \n",
       "\n",
       "  koi_pdisposition  koi_score  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  \\\n",
       "0        CANDIDATE      1.000              0              0              0   \n",
       "1        CANDIDATE      0.969              0              0              0   \n",
       "2        CANDIDATE      0.000              0              0              0   \n",
       "3   FALSE POSITIVE      0.000              0              1              0   \n",
       "4        CANDIDATE      1.000              0              0              0   \n",
       "\n",
       "   koi_fpflag_ec  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns needed for ExoNet\n",
    "selected_columns = [\n",
    "    # Core features\n",
    "    \"koi_period\",\n",
    "    \"koi_duration\",\n",
    "    \"koi_depth\",\n",
    "    \"koi_prad\",\n",
    "    \"koi_model_snr\",\n",
    "\n",
    "    # Auxiliary features\n",
    "    \"koi_time0bk\",\n",
    "    \"koi_impact\",\n",
    "\n",
    "    # Stellar context\n",
    "    \"koi_steff\",\n",
    "    \"koi_slogg\",\n",
    "    \"koi_srad\",\n",
    "    \"koi_kepmag\",\n",
    "\n",
    "    # Labels / metadata\n",
    "    \"koi_disposition\",\n",
    "    \"koi_pdisposition\",\n",
    "    \"koi_score\",\n",
    "    \"koi_fpflag_nt\",\n",
    "    \"koi_fpflag_ss\",\n",
    "    \"koi_fpflag_co\",\n",
    "    \"koi_fpflag_ec\"\n",
    "]\n",
    "\n",
    "# Filter dataframe\n",
    "exo_df = df[selected_columns]\n",
    "\n",
    "# Quick look at the shape & first rows\n",
    "print(\"Selected shape:\", exo_df.shape)\n",
    "exo_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a0c1128d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (7651, 16)\n",
      "Test shape: (1913, 16)\n",
      "Class distribution:\n",
      " label\n",
      "0    4839\n",
      "2    2746\n",
      "1    1979\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "exo_df = exo_df.dropna(subset=[\"koi_disposition\"])  # must have a label\n",
    "exo_df = exo_df.fillna(df.mean(numeric_only=True))  # fill numeric NaNs with mean\n",
    "\n",
    "# 4. Encode labels (target variable)\n",
    "label_map = {\"FALSE POSITIVE\": 0, \"CANDIDATE\": 1, \"CONFIRMED\": 2}\n",
    "exo_df[\"label\"] = exo_df[\"koi_disposition\"].map(label_map)\n",
    "\n",
    "# Drop raw label columns we don’t use directly\n",
    "exo_df = exo_df.drop(columns=[\"koi_disposition\", \"koi_pdisposition\"])\n",
    "\n",
    "# 5. Split features & labels\n",
    "X = exo_df.drop(columns=[\"label\"])\n",
    "y = exo_df[\"label\"]\n",
    "\n",
    "# 6. Identify numeric features to scale\n",
    "numeric_features = [\n",
    "    \"koi_period\", \"koi_duration\", \"koi_depth\", \"koi_prad\", \"koi_model_snr\",\n",
    "    \"koi_time0bk\", \"koi_impact\",\n",
    "    \"koi_steff\", \"koi_slogg\", \"koi_srad\", \"koi_kepmag\", \"koi_score\"\n",
    "]\n",
    "\n",
    "binary_features = [\"koi_fpflag_nt\", \"koi_fpflag_ss\", \"koi_fpflag_co\", \"koi_fpflag_ec\"]\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = X.copy()\n",
    "X_scaled[numeric_features] = scaler.fit_transform(X[numeric_features])\n",
    "\n",
    "# Binary features stay as is\n",
    "\n",
    "# 7. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "print(\"Class distribution:\\n\", y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b938f44c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5acbc293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize class distribution for the target column \"label\"\n",
    "plt.figure(figsize=(6,4))\n",
    "y.value_counts().plot(kind='bar', color=['tomato', 'gold', 'dodgerblue'])\n",
    "plt.xticks(ticks=[0,1,2], labels=[\"FALSE POSITIVE\", \"CANDIDATE\", \"CONFIRMED\"], rotation=30)\n",
    "plt.title(\"Class Distribution for Target (label)\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c54c2763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (4749, 16)\n",
      "Test shape: (1188, 16)\n",
      "Class distribution:\n",
      " label\n",
      "2    1979\n",
      "1    1979\n",
      "0    1979\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "exo_df_balanced = exo_df.copy()\n",
    "\n",
    "# Find the minimum class count\n",
    "min_count = exo_df_balanced['label'].value_counts().min()\n",
    "\n",
    "# Downsample each class to the minimum count\n",
    "balanced_df = pd.concat([\n",
    "    resample(exo_df_balanced[exo_df_balanced['label'] == c], \n",
    "             replace=False, \n",
    "             n_samples=min_count, \n",
    "             random_state=42)\n",
    "    for c in exo_df_balanced['label'].unique()\n",
    "])\n",
    "\n",
    "# 5. Split features & labels\n",
    "X = balanced_df.drop(columns=[\"label\"])\n",
    "y = balanced_df[\"label\"]\n",
    "\n",
    "# 6. Identify numeric features to scale\n",
    "numeric_features = [\n",
    "    \"koi_period\", \"koi_duration\", \"koi_depth\", \"koi_prad\", \"koi_model_snr\",\n",
    "    \"koi_time0bk\", \"koi_impact\",\n",
    "    \"koi_steff\", \"koi_slogg\", \"koi_srad\", \"koi_kepmag\", \"koi_score\"\n",
    "]\n",
    "\n",
    "binary_features = [\"koi_fpflag_nt\", \"koi_fpflag_ss\", \"koi_fpflag_co\", \"koi_fpflag_ec\"]\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = X.copy()\n",
    "X_scaled[numeric_features] = scaler.fit_transform(X[numeric_features])\n",
    "\n",
    "# Binary features stay as is\n",
    "\n",
    "# 7. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "print(\"Class distribution:\\n\", y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d625944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ed0dabe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_kepmag</th>\n",
       "      <th>koi_score</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4749.000000</td>\n",
       "      <td>4749.000000</td>\n",
       "      <td>4749.000000</td>\n",
       "      <td>4749.000000</td>\n",
       "      <td>4749.000000</td>\n",
       "      <td>4749.000000</td>\n",
       "      <td>4749.000000</td>\n",
       "      <td>4749.000000</td>\n",
       "      <td>4749.000000</td>\n",
       "      <td>4749.000000</td>\n",
       "      <td>4749.000000</td>\n",
       "      <td>4749.000000</td>\n",
       "      <td>4749.000000</td>\n",
       "      <td>4749.000000</td>\n",
       "      <td>4749.000000</td>\n",
       "      <td>4749.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.012569</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>0.006051</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.012064</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.012315</td>\n",
       "      <td>-0.000647</td>\n",
       "      <td>-0.006154</td>\n",
       "      <td>-0.001113</td>\n",
       "      <td>-0.001266</td>\n",
       "      <td>0.105075</td>\n",
       "      <td>0.154980</td>\n",
       "      <td>0.128238</td>\n",
       "      <td>0.076858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.079382</td>\n",
       "      <td>1.005284</td>\n",
       "      <td>1.012430</td>\n",
       "      <td>1.088204</td>\n",
       "      <td>1.044476</td>\n",
       "      <td>1.012721</td>\n",
       "      <td>1.011250</td>\n",
       "      <td>0.994741</td>\n",
       "      <td>0.983743</td>\n",
       "      <td>0.889758</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>0.998432</td>\n",
       "      <td>0.306682</td>\n",
       "      <td>0.361924</td>\n",
       "      <td>0.334389</td>\n",
       "      <td>0.266395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.051612</td>\n",
       "      <td>-0.971230</td>\n",
       "      <td>-0.256809</td>\n",
       "      <td>-0.038750</td>\n",
       "      <td>-0.293540</td>\n",
       "      <td>-0.697940</td>\n",
       "      <td>-0.219426</td>\n",
       "      <td>-3.993017</td>\n",
       "      <td>-11.040348</td>\n",
       "      <td>-0.259897</td>\n",
       "      <td>-5.391132</td>\n",
       "      <td>-1.419615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.049618</td>\n",
       "      <td>-0.538659</td>\n",
       "      <td>-0.254426</td>\n",
       "      <td>-0.038021</td>\n",
       "      <td>-0.276595</td>\n",
       "      <td>-0.511748</td>\n",
       "      <td>-0.162656</td>\n",
       "      <td>-0.448728</td>\n",
       "      <td>-0.208852</td>\n",
       "      <td>-0.132363</td>\n",
       "      <td>-0.586608</td>\n",
       "      <td>-1.417230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.044997</td>\n",
       "      <td>-0.289378</td>\n",
       "      <td>-0.250728</td>\n",
       "      <td>-0.037505</td>\n",
       "      <td>-0.261712</td>\n",
       "      <td>-0.433597</td>\n",
       "      <td>-0.055569</td>\n",
       "      <td>0.076352</td>\n",
       "      <td>0.270828</td>\n",
       "      <td>-0.102149</td>\n",
       "      <td>0.191646</td>\n",
       "      <td>0.354910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.024173</td>\n",
       "      <td>0.137591</td>\n",
       "      <td>-0.237844</td>\n",
       "      <td>-0.034256</td>\n",
       "      <td>-0.192900</td>\n",
       "      <td>0.055046</td>\n",
       "      <td>0.043455</td>\n",
       "      <td>0.529830</td>\n",
       "      <td>0.541616</td>\n",
       "      <td>-0.034693</td>\n",
       "      <td>0.762612</td>\n",
       "      <td>0.963114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.243467</td>\n",
       "      <td>15.194113</td>\n",
       "      <td>13.125309</td>\n",
       "      <td>63.129061</td>\n",
       "      <td>13.048572</td>\n",
       "      <td>10.883093</td>\n",
       "      <td>32.295884</td>\n",
       "      <td>7.541501</td>\n",
       "      <td>2.671810</td>\n",
       "      <td>28.306231</td>\n",
       "      <td>3.838009</td>\n",
       "      <td>0.965499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        koi_period  koi_duration    koi_depth     koi_prad  koi_model_snr  \\\n",
       "count  4749.000000   4749.000000  4749.000000  4749.000000    4749.000000   \n",
       "mean     -0.012569      0.002746     0.006051     0.002126       0.012064   \n",
       "std       0.079382      1.005284     1.012430     1.088204       1.044476   \n",
       "min      -0.051612     -0.971230    -0.256809    -0.038750      -0.293540   \n",
       "25%      -0.049618     -0.538659    -0.254426    -0.038021      -0.276595   \n",
       "50%      -0.044997     -0.289378    -0.250728    -0.037505      -0.261712   \n",
       "75%      -0.024173      0.137591    -0.237844    -0.034256      -0.192900   \n",
       "max       1.243467     15.194113    13.125309    63.129061      13.048572   \n",
       "\n",
       "       koi_time0bk   koi_impact    koi_steff    koi_slogg     koi_srad  \\\n",
       "count  4749.000000  4749.000000  4749.000000  4749.000000  4749.000000   \n",
       "mean      0.005675     0.000394     0.012315    -0.000647    -0.006154   \n",
       "std       1.012721     1.011250     0.994741     0.983743     0.889758   \n",
       "min      -0.697940    -0.219426    -3.993017   -11.040348    -0.259897   \n",
       "25%      -0.511748    -0.162656    -0.448728    -0.208852    -0.132363   \n",
       "50%      -0.433597    -0.055569     0.076352     0.270828    -0.102149   \n",
       "75%       0.055046     0.043455     0.529830     0.541616    -0.034693   \n",
       "max      10.883093    32.295884     7.541501     2.671810    28.306231   \n",
       "\n",
       "        koi_kepmag    koi_score  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  \\\n",
       "count  4749.000000  4749.000000    4749.000000    4749.000000    4749.000000   \n",
       "mean     -0.001113    -0.001266       0.105075       0.154980       0.128238   \n",
       "std       0.999066     0.998432       0.306682       0.361924       0.334389   \n",
       "min      -5.391132    -1.419615       0.000000       0.000000       0.000000   \n",
       "25%      -0.586608    -1.417230       0.000000       0.000000       0.000000   \n",
       "50%       0.191646     0.354910       0.000000       0.000000       0.000000   \n",
       "75%       0.762612     0.963114       0.000000       0.000000       0.000000   \n",
       "max       3.838009     0.965499       1.000000       1.000000       1.000000   \n",
       "\n",
       "       koi_fpflag_ec  \n",
       "count    4749.000000  \n",
       "mean        0.076858  \n",
       "std         0.266395  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "67daa4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2561    2\n",
       "7584    1\n",
       "864     1\n",
       "4524    0\n",
       "134     0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c11e89b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8956228956228957\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Fit a Random Forest model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Print accuracy\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "df0eaf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "FALSE POSITIVE       0.99      0.96      0.98       396\n",
      "     CANDIDATE       0.82      0.88      0.85       396\n",
      "     CONFIRMED       0.88      0.85      0.86       396\n",
      "\n",
      "      accuracy                           0.90      1188\n",
      "     macro avg       0.90      0.90      0.90      1188\n",
      "  weighted avg       0.90      0.90      0.90      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=[\"FALSE POSITIVE\", \"CANDIDATE\", \"CONFIRMED\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3753e0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Test accuracy: 0.7558922558922558\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "FALSE POSITIVE       0.99      0.96      0.98       396\n",
      "     CANDIDATE       0.86      0.33      0.48       396\n",
      "     CONFIRMED       0.59      0.97      0.73       396\n",
      "\n",
      "      accuracy                           0.76      1188\n",
      "     macro avg       0.81      0.76      0.73      1188\n",
      "  weighted avg       0.81      0.76      0.73      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Fit a Naive Bayes model\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_nb_pred = nb.predict(X_test)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(\"Naive Bayes Test accuracy:\", accuracy_score(y_test, y_nb_pred))\n",
    "print(classification_report(y_test, y_nb_pred, target_names=[\"FALSE POSITIVE\", \"CANDIDATE\", \"CONFIRMED\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8ce12941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep NN Test accuracy: 0.8535353535353535\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "FALSE POSITIVE       1.00      0.96      0.98       396\n",
      "     CANDIDATE       0.75      0.85      0.80       396\n",
      "     CONFIRMED       0.83      0.75      0.79       396\n",
      "\n",
      "      accuracy                           0.85      1188\n",
      "     macro avg       0.86      0.85      0.85      1188\n",
      "  weighted avg       0.86      0.85      0.85      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create a deep neural network model (multi-layer perceptron)\n",
    "dnn = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64, 32),  # 3 hidden layers, can adjust sizes\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=200,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "dnn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_dnn_pred = dnn.predict(X_test)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(\"Deep NN Test accuracy:\", accuracy_score(y_test, y_dnn_pred))\n",
    "print(classification_report(y_test, y_dnn_pred, target_names=[\"FALSE POSITIVE\", \"CANDIDATE\", \"CONFIRMED\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d96ec6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Assume you have these (replace with your actual data)\n",
    "# X_train: np.array or torch.Tensor, shape [n_samples, input_size]\n",
    "# y_train: np.array or torch.Tensor, shape [n_samples], values 0-2\n",
    "# X_test, y_test: similar\n",
    "\n",
    "# Convert to tensors if not already\n",
    "X_train = torch.tensor(X_train.to_numpy(), dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
    "X_test = torch.tensor(X_test.to_numpy(), dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.to_numpy(), dtype=torch.long)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Data loaders\n",
    "batch_size = 32  # Adjust based on your data size and memory\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Compute class weights for imbalance (optional but recommended for recall)\n",
    "class_counts = np.bincount(y_train.numpy())\n",
    "class_weights = 1. / class_counts\n",
    "class_weights = torch.tensor(class_weights / class_weights.sum(), dtype=torch.float32)  # Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "314416f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4749, 16])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "24775b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout_rate=0.3):  # <-- fixed __init__\n",
    "        super(ResidualBlock, self).__init__()  # <-- fixed __init__\n",
    "        self.fc = nn.Linear(in_features, out_features)\n",
    "        self.ln = nn.LayerNorm(out_features)  # Layer norm for better stability\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Projection if dimensions differ\n",
    "        self.proj = nn.Linear(in_features, out_features) if in_features != out_features else nn.Identity()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = self.proj(x)\n",
    "        x = F.silu(self.ln(self.fc(x)))  # Swish activation\n",
    "        x = self.dropout(x)\n",
    "        return x + residual  # Skip connection\n",
    "\n",
    "\n",
    "class ResidualMLP(nn.Module):\n",
    "    def __init__(self, input_size=16, num_classes=3):  # <-- fixed __init__\n",
    "        super(ResidualMLP, self).__init__()  # <-- fixed __init__\n",
    "        self.entry = nn.Linear(input_size, 256)  # Entry layer\n",
    "        \n",
    "        # Residual blocks for depth\n",
    "        self.res_block1 = ResidualBlock(256, 256)\n",
    "        self.res_block2 = ResidualBlock(256, 128)\n",
    "        self.res_block3 = ResidualBlock(128, 128)\n",
    "        self.res_block4 = ResidualBlock(128, 64)\n",
    "        \n",
    "        self.dropout_final = nn.Dropout(0.2)\n",
    "        self.fc_out = nn.Linear(64, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.silu(self.entry(x))\n",
    "        \n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = self.res_block3(x)\n",
    "        x = self.res_block4(x)\n",
    "        \n",
    "        x = self.dropout_final(x)\n",
    "        x = self.fc_out(x)  # Logits output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aed47ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):  # <-- fixed __init__\n",
    "        super(FocalLoss, self).__init__() \n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  # Can be a tensor of class weights\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        return focal_loss.sum()\n",
    "loss_fn = FocalLoss(alpha=None, gamma=2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2e2205d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Name: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "Number of GPUs: 1\n",
      "Current Device Index: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"Current Device Index:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5c3417b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved new best model at epoch 1 with Test Accuracy: 82.32%\n",
      "Epoch 1/300 | Train Loss: 0.1864, Train Acc: 74.35% | Test Loss: 0.1172, Test Acc: 82.32%\n",
      "Epoch 2/300 | Train Loss: 0.1371, Train Acc: 79.39% | Test Loss: 0.1232, Test Acc: 81.73%\n",
      "✅ Saved new best model at epoch 3 with Test Accuracy: 82.66%\n",
      "Epoch 3/300 | Train Loss: 0.1223, Train Acc: 80.69% | Test Loss: 0.1165, Test Acc: 82.66%\n",
      "Epoch 4/300 | Train Loss: 0.1141, Train Acc: 81.70% | Test Loss: 0.1173, Test Acc: 82.15%\n",
      "✅ Saved new best model at epoch 5 with Test Accuracy: 83.08%\n",
      "Epoch 5/300 | Train Loss: 0.1113, Train Acc: 81.93% | Test Loss: 0.1221, Test Acc: 83.08%\n",
      "Epoch 6/300 | Train Loss: 0.1067, Train Acc: 83.11% | Test Loss: 0.1049, Test Acc: 82.66%\n",
      "Epoch 7/300 | Train Loss: 0.1074, Train Acc: 82.48% | Test Loss: 0.1219, Test Acc: 82.66%\n",
      "Epoch 8/300 | Train Loss: 0.1123, Train Acc: 82.44% | Test Loss: 0.1113, Test Acc: 82.74%\n",
      "Epoch 9/300 | Train Loss: 0.1053, Train Acc: 82.44% | Test Loss: 0.1187, Test Acc: 81.48%\n",
      "Epoch 10/300 | Train Loss: 0.1045, Train Acc: 82.88% | Test Loss: 0.1154, Test Acc: 82.58%\n",
      "Epoch 11/300 | Train Loss: 0.1021, Train Acc: 82.50% | Test Loss: 0.1094, Test Acc: 82.49%\n",
      "📉 Learning rate reduced from 0.001000 to 0.000500\n",
      "Epoch 12/300 | Train Loss: 0.1015, Train Acc: 82.80% | Test Loss: 0.1039, Test Acc: 82.66%\n",
      "✅ Saved new best model at epoch 13 with Test Accuracy: 83.25%\n",
      "Epoch 13/300 | Train Loss: 0.0983, Train Acc: 83.05% | Test Loss: 0.1010, Test Acc: 83.25%\n",
      "✅ Saved new best model at epoch 14 with Test Accuracy: 84.18%\n",
      "Epoch 14/300 | Train Loss: 0.0957, Train Acc: 83.05% | Test Loss: 0.0966, Test Acc: 84.18%\n",
      "Epoch 15/300 | Train Loss: 0.0962, Train Acc: 83.66% | Test Loss: 0.1074, Test Acc: 82.91%\n",
      "Epoch 16/300 | Train Loss: 0.0955, Train Acc: 84.06% | Test Loss: 0.1029, Test Acc: 83.67%\n",
      "Epoch 17/300 | Train Loss: 0.0940, Train Acc: 83.81% | Test Loss: 0.1159, Test Acc: 82.83%\n",
      "Epoch 18/300 | Train Loss: 0.0957, Train Acc: 83.22% | Test Loss: 0.0964, Test Acc: 83.92%\n",
      "Epoch 19/300 | Train Loss: 0.0947, Train Acc: 83.68% | Test Loss: 0.1107, Test Acc: 83.92%\n",
      "Epoch 20/300 | Train Loss: 0.0938, Train Acc: 83.77% | Test Loss: 0.1238, Test Acc: 83.16%\n",
      "✅ Saved new best model at epoch 21 with Test Accuracy: 84.60%\n",
      "Epoch 21/300 | Train Loss: 0.0948, Train Acc: 84.21% | Test Loss: 0.1023, Test Acc: 84.60%\n",
      "Epoch 22/300 | Train Loss: 0.0931, Train Acc: 84.12% | Test Loss: 0.1129, Test Acc: 84.01%\n",
      "Epoch 23/300 | Train Loss: 0.0931, Train Acc: 83.66% | Test Loss: 0.1076, Test Acc: 82.15%\n",
      "Epoch 24/300 | Train Loss: 0.0927, Train Acc: 83.93% | Test Loss: 0.1061, Test Acc: 83.84%\n",
      "Epoch 25/300 | Train Loss: 0.0918, Train Acc: 84.06% | Test Loss: 0.1001, Test Acc: 84.26%\n",
      "Epoch 26/300 | Train Loss: 0.0920, Train Acc: 84.04% | Test Loss: 0.1058, Test Acc: 83.00%\n",
      "Epoch 27/300 | Train Loss: 0.0918, Train Acc: 83.58% | Test Loss: 0.1092, Test Acc: 83.08%\n",
      "📉 Learning rate reduced from 0.000500 to 0.000250\n",
      "Epoch 28/300 | Train Loss: 0.0915, Train Acc: 83.93% | Test Loss: 0.1051, Test Acc: 84.26%\n",
      "✅ Saved new best model at epoch 29 with Test Accuracy: 84.68%\n",
      "Epoch 29/300 | Train Loss: 0.0872, Train Acc: 84.80% | Test Loss: 0.0981, Test Acc: 84.68%\n",
      "Epoch 30/300 | Train Loss: 0.0859, Train Acc: 85.01% | Test Loss: 0.1070, Test Acc: 83.16%\n",
      "✅ Saved new best model at epoch 31 with Test Accuracy: 85.19%\n",
      "Epoch 31/300 | Train Loss: 0.0876, Train Acc: 84.52% | Test Loss: 0.0975, Test Acc: 85.19%\n",
      "Epoch 32/300 | Train Loss: 0.0853, Train Acc: 84.97% | Test Loss: 0.1013, Test Acc: 84.68%\n",
      "Epoch 33/300 | Train Loss: 0.0845, Train Acc: 84.92% | Test Loss: 0.1077, Test Acc: 83.33%\n",
      "Epoch 34/300 | Train Loss: 0.0859, Train Acc: 84.73% | Test Loss: 0.1079, Test Acc: 82.91%\n",
      "Epoch 35/300 | Train Loss: 0.0854, Train Acc: 84.82% | Test Loss: 0.1127, Test Acc: 83.16%\n",
      "Epoch 36/300 | Train Loss: 0.0847, Train Acc: 85.05% | Test Loss: 0.1072, Test Acc: 85.10%\n",
      "✅ Saved new best model at epoch 37 with Test Accuracy: 85.35%\n",
      "Epoch 37/300 | Train Loss: 0.0855, Train Acc: 84.48% | Test Loss: 0.1035, Test Acc: 85.35%\n",
      "Epoch 38/300 | Train Loss: 0.0840, Train Acc: 85.26% | Test Loss: 0.1116, Test Acc: 85.10%\n",
      "✅ Saved new best model at epoch 39 with Test Accuracy: 85.44%\n",
      "Epoch 39/300 | Train Loss: 0.0845, Train Acc: 84.80% | Test Loss: 0.1061, Test Acc: 85.44%\n",
      "Epoch 40/300 | Train Loss: 0.0828, Train Acc: 85.53% | Test Loss: 0.1047, Test Acc: 84.60%\n",
      "Epoch 41/300 | Train Loss: 0.0830, Train Acc: 85.18% | Test Loss: 0.1041, Test Acc: 85.35%\n",
      "✅ Saved new best model at epoch 42 with Test Accuracy: 85.77%\n",
      "Epoch 42/300 | Train Loss: 0.0833, Train Acc: 85.09% | Test Loss: 0.1112, Test Acc: 85.77%\n",
      "Epoch 43/300 | Train Loss: 0.0837, Train Acc: 84.97% | Test Loss: 0.0982, Test Acc: 85.44%\n",
      "Epoch 44/300 | Train Loss: 0.0839, Train Acc: 85.03% | Test Loss: 0.0999, Test Acc: 85.27%\n",
      "Epoch 45/300 | Train Loss: 0.0826, Train Acc: 85.26% | Test Loss: 0.0998, Test Acc: 84.43%\n",
      "Epoch 46/300 | Train Loss: 0.0823, Train Acc: 85.30% | Test Loss: 0.1051, Test Acc: 85.52%\n",
      "Epoch 47/300 | Train Loss: 0.0815, Train Acc: 85.68% | Test Loss: 0.1018, Test Acc: 84.93%\n",
      "✅ Saved new best model at epoch 48 with Test Accuracy: 85.94%\n",
      "Epoch 48/300 | Train Loss: 0.0801, Train Acc: 85.60% | Test Loss: 0.1064, Test Acc: 85.94%\n",
      "✅ Saved new best model at epoch 49 with Test Accuracy: 86.11%\n",
      "Epoch 49/300 | Train Loss: 0.0809, Train Acc: 84.88% | Test Loss: 0.1052, Test Acc: 86.11%\n",
      "Epoch 50/300 | Train Loss: 0.0819, Train Acc: 85.87% | Test Loss: 0.1021, Test Acc: 84.34%\n",
      "Epoch 51/300 | Train Loss: 0.0832, Train Acc: 85.24% | Test Loss: 0.0964, Test Acc: 86.03%\n",
      "✅ Saved new best model at epoch 52 with Test Accuracy: 86.53%\n",
      "Epoch 52/300 | Train Loss: 0.0807, Train Acc: 85.95% | Test Loss: 0.1007, Test Acc: 86.53%\n",
      "Epoch 53/300 | Train Loss: 0.0800, Train Acc: 85.62% | Test Loss: 0.1048, Test Acc: 85.02%\n",
      "Epoch 54/300 | Train Loss: 0.0822, Train Acc: 85.81% | Test Loss: 0.1004, Test Acc: 84.01%\n",
      "Epoch 55/300 | Train Loss: 0.0794, Train Acc: 85.66% | Test Loss: 0.1058, Test Acc: 84.68%\n",
      "Epoch 56/300 | Train Loss: 0.0808, Train Acc: 85.79% | Test Loss: 0.1054, Test Acc: 84.76%\n",
      "Epoch 57/300 | Train Loss: 0.0805, Train Acc: 85.45% | Test Loss: 0.1044, Test Acc: 85.02%\n",
      "Epoch 58/300 | Train Loss: 0.0787, Train Acc: 85.87% | Test Loss: 0.1003, Test Acc: 85.94%\n",
      "📉 Learning rate reduced from 0.000250 to 0.000125\n",
      "Epoch 59/300 | Train Loss: 0.0791, Train Acc: 86.36% | Test Loss: 0.1026, Test Acc: 86.28%\n",
      "Epoch 60/300 | Train Loss: 0.0758, Train Acc: 86.63% | Test Loss: 0.1004, Test Acc: 85.19%\n",
      "Epoch 61/300 | Train Loss: 0.0763, Train Acc: 86.71% | Test Loss: 0.1039, Test Acc: 85.44%\n",
      "✅ Saved new best model at epoch 62 with Test Accuracy: 86.62%\n",
      "Epoch 62/300 | Train Loss: 0.0756, Train Acc: 86.44% | Test Loss: 0.1064, Test Acc: 86.62%\n",
      "Epoch 63/300 | Train Loss: 0.0758, Train Acc: 86.76% | Test Loss: 0.1045, Test Acc: 85.61%\n",
      "Epoch 64/300 | Train Loss: 0.0744, Train Acc: 86.94% | Test Loss: 0.1028, Test Acc: 86.20%\n",
      "Epoch 65/300 | Train Loss: 0.0766, Train Acc: 85.81% | Test Loss: 0.1082, Test Acc: 86.20%\n",
      "Epoch 66/300 | Train Loss: 0.0736, Train Acc: 87.22% | Test Loss: 0.1082, Test Acc: 86.28%\n",
      "Epoch 67/300 | Train Loss: 0.0750, Train Acc: 86.59% | Test Loss: 0.1035, Test Acc: 86.11%\n",
      "✅ Saved new best model at epoch 68 with Test Accuracy: 86.78%\n",
      "Epoch 68/300 | Train Loss: 0.0731, Train Acc: 86.76% | Test Loss: 0.1074, Test Acc: 86.78%\n",
      "Epoch 69/300 | Train Loss: 0.0761, Train Acc: 87.05% | Test Loss: 0.1027, Test Acc: 86.36%\n",
      "Epoch 70/300 | Train Loss: 0.0732, Train Acc: 87.16% | Test Loss: 0.1008, Test Acc: 86.70%\n",
      "Epoch 71/300 | Train Loss: 0.0739, Train Acc: 87.34% | Test Loss: 0.1026, Test Acc: 86.78%\n",
      "Epoch 72/300 | Train Loss: 0.0742, Train Acc: 87.05% | Test Loss: 0.1052, Test Acc: 86.11%\n",
      "Epoch 73/300 | Train Loss: 0.0733, Train Acc: 87.11% | Test Loss: 0.1103, Test Acc: 86.36%\n",
      "✅ Saved new best model at epoch 74 with Test Accuracy: 86.95%\n",
      "Epoch 74/300 | Train Loss: 0.0746, Train Acc: 86.50% | Test Loss: 0.1081, Test Acc: 86.95%\n",
      "Epoch 75/300 | Train Loss: 0.0735, Train Acc: 87.58% | Test Loss: 0.1089, Test Acc: 86.53%\n",
      "Epoch 76/300 | Train Loss: 0.0733, Train Acc: 87.58% | Test Loss: 0.1114, Test Acc: 86.11%\n",
      "Epoch 77/300 | Train Loss: 0.0717, Train Acc: 87.43% | Test Loss: 0.1103, Test Acc: 85.94%\n",
      "Epoch 78/300 | Train Loss: 0.0720, Train Acc: 87.05% | Test Loss: 0.1053, Test Acc: 86.28%\n",
      "Epoch 79/300 | Train Loss: 0.0718, Train Acc: 87.51% | Test Loss: 0.1065, Test Acc: 86.70%\n",
      "Epoch 80/300 | Train Loss: 0.0709, Train Acc: 87.41% | Test Loss: 0.1051, Test Acc: 85.69%\n",
      "📉 Learning rate reduced from 0.000125 to 0.000063\n",
      "Epoch 81/300 | Train Loss: 0.0725, Train Acc: 87.49% | Test Loss: 0.0969, Test Acc: 86.70%\n",
      "Epoch 82/300 | Train Loss: 0.0706, Train Acc: 87.62% | Test Loss: 0.0980, Test Acc: 86.87%\n",
      "✅ Saved new best model at epoch 83 with Test Accuracy: 87.12%\n",
      "Epoch 83/300 | Train Loss: 0.0710, Train Acc: 87.68% | Test Loss: 0.1047, Test Acc: 87.12%\n",
      "Epoch 84/300 | Train Loss: 0.0703, Train Acc: 87.70% | Test Loss: 0.1047, Test Acc: 86.70%\n",
      "Epoch 85/300 | Train Loss: 0.0717, Train Acc: 87.91% | Test Loss: 0.1051, Test Acc: 86.45%\n",
      "Epoch 86/300 | Train Loss: 0.0700, Train Acc: 88.00% | Test Loss: 0.1084, Test Acc: 86.62%\n",
      "✅ Saved new best model at epoch 87 with Test Accuracy: 87.29%\n",
      "Epoch 87/300 | Train Loss: 0.0701, Train Acc: 87.34% | Test Loss: 0.1030, Test Acc: 87.29%\n",
      "Epoch 88/300 | Train Loss: 0.0686, Train Acc: 88.19% | Test Loss: 0.1073, Test Acc: 86.70%\n",
      "Epoch 89/300 | Train Loss: 0.0700, Train Acc: 87.91% | Test Loss: 0.1034, Test Acc: 87.04%\n",
      "Epoch 90/300 | Train Loss: 0.0694, Train Acc: 88.21% | Test Loss: 0.1035, Test Acc: 86.36%\n",
      "Epoch 91/300 | Train Loss: 0.0696, Train Acc: 88.50% | Test Loss: 0.1033, Test Acc: 86.95%\n",
      "Epoch 92/300 | Train Loss: 0.0690, Train Acc: 88.10% | Test Loss: 0.1052, Test Acc: 86.87%\n",
      "Epoch 93/300 | Train Loss: 0.0678, Train Acc: 87.87% | Test Loss: 0.1057, Test Acc: 87.21%\n",
      "📉 Learning rate reduced from 0.000063 to 0.000031\n",
      "Epoch 94/300 | Train Loss: 0.0688, Train Acc: 88.21% | Test Loss: 0.1060, Test Acc: 86.53%\n",
      "Epoch 95/300 | Train Loss: 0.0689, Train Acc: 87.93% | Test Loss: 0.1071, Test Acc: 86.62%\n",
      "Epoch 96/300 | Train Loss: 0.0676, Train Acc: 88.46% | Test Loss: 0.1071, Test Acc: 86.62%\n",
      "Epoch 97/300 | Train Loss: 0.0681, Train Acc: 88.40% | Test Loss: 0.1050, Test Acc: 87.12%\n",
      "Epoch 98/300 | Train Loss: 0.0673, Train Acc: 88.38% | Test Loss: 0.1036, Test Acc: 86.87%\n",
      "Epoch 99/300 | Train Loss: 0.0673, Train Acc: 88.42% | Test Loss: 0.1052, Test Acc: 87.04%\n",
      "⏹️ Early stopping triggered at epoch 99\n",
      "\n",
      "🎯 Training finished. Best Test Accuracy: 87.29%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize model\n",
    "input_size = X_train.shape[1]  # number of features\n",
    "model = ResidualMLP(input_size=input_size, num_classes=3).to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Learning rate scheduler (ReduceLROnPlateau equivalent)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=6, min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Early stopping setup\n",
    "patience = 12\n",
    "best_accuracy = 0.0\n",
    "epochs_no_improve = 0\n",
    "best_model_path = \"best_residual_mlp_model.pth\"\n",
    "\n",
    "# Training loop\n",
    "epochs = 300\n",
    "for epoch in range(epochs):\n",
    "    # --- Training ---\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        \n",
    "        loss = loss_fn(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "\n",
    "    # --- Evaluation on test set ---\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            loss = loss_fn(outputs, batch_y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_test += batch_y.size(0)\n",
    "            correct_test += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_accuracy = 100 * correct_test / total_test\n",
    "\n",
    "    # --- Scheduler step ---\n",
    "    old_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(test_accuracy)\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    if new_lr < old_lr:\n",
    "        print(f\"📉 Learning rate reduced from {old_lr:.6f} to {new_lr:.6f}\")\n",
    "\n",
    "    # --- Save best model ---\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"✅ Saved new best model at epoch {epoch+1} with Test Accuracy: {best_accuracy:.2f}%\")\n",
    "        epochs_no_improve = 0  # reset patience counter\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    # --- Logging ---\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{epochs} | \"\n",
    "        f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}% | \"\n",
    "        f\"Test Loss: {avg_test_loss:.4f}, Test Acc: {test_accuracy:.2f}%\"\n",
    "    )\n",
    "\n",
    "    # --- Early stopping ---\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"⏹️ Early stopping triggered at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\n🎯 Training finished. Best Test Accuracy: {best_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb61b1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Learning rate scheduler (ReduceLROnPlateau equivalent)\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReduceLROnPlateau\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Early stopping setup\u001b[39;00m\n\u001b[0;32m     21\u001b[0m patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'verbose'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize model\n",
    "input_size = X_train.shape[1]  # number of features\n",
    "model = ResidualMLP(input_size=input_size, num_classes=3).to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Learning rate scheduler (ReduceLROnPlateau equivalent)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.5, patience=6, min_lr=1e-6\n",
    ")\n",
    "\n",
    "# Early stopping setup\n",
    "patience = 12\n",
    "best_accuracy = 0.0\n",
    "epochs_no_improve = 0\n",
    "best_model_path = \"best_residual_mlp_model.pth\"\n",
    "\n",
    "# Training loop\n",
    "epochs = 300  # Adjust as needed\n",
    "for epoch in range(epochs):\n",
    "    # --- Training ---\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "\n",
    "    # --- Evaluation on test set ---\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X)\n",
    "            loss = loss_fn(outputs, batch_y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_test += batch_y.size(0)\n",
    "            correct_test += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_accuracy = 100 * correct_test / total_test\n",
    "\n",
    "    # --- Scheduler step (uses validation accuracy) ---\n",
    "    scheduler.step(test_accuracy)\n",
    "\n",
    "    # --- Checkpointing (save best model) ---\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"✅ Saved new best model at epoch {epoch+1} with Test Accuracy: {best_accuracy:.2f}%\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    # --- Early Stopping ---\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"⏹ Early stopping triggered at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "    # --- Logging ---\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{epochs} | \"\n",
    "        f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}% | \"\n",
    "        f\"Test Loss: {avg_test_loss:.4f}, Test Acc: {test_accuracy:.2f}%\"\n",
    "    )\n",
    "\n",
    "print(f\"\\n🎯 Training finished. Best Test Accuracy: {best_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9267faed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9871    0.9672    0.9770       396\n",
      "           1     0.7753    0.8712    0.8205       396\n",
      "           2     0.8704    0.7803    0.8229       396\n",
      "\n",
      "    accuracy                         0.8729      1188\n",
      "   macro avg     0.8776    0.8729    0.8735      1188\n",
      "weighted avg     0.8776    0.8729    0.8735      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- Evaluate on test set and generate classification report ---\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "# Generate report\n",
    "print(\"\\n📊 Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49371989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
